# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14inzDPR2jqxsWnwc8CcUNryApcgnQh4_
"""

import streamlit as st
import numpy as np
import tensorflow as tf
import cv2
from streamlit_drawable_canvas import st_canvas

# 1. Load model
@st.cache_resource
def load_model():
    return tf.keras.models.load_model('mnist_model.h5', compile=False)

model = load_model()

st.title("Handwriting Digit Recognizer")
st.markdown("Draw a digit (0-9) inside the box below:")

# 2. Canvas
canvas_result = st_canvas(
    stroke_width=15,
    stroke_color="#FFFFFF",
    background_color="#000000",
    height=150,
    width=150,
    drawing_mode="freedraw",
    key="canvas",
)

# --- THE NEW MAGIC FUNCTION ---
def process_image(img_data):
    # 1. Convert to grayscale
    img = img_data.astype('uint8')
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # 2. Find the bounding box of the drawn digit
    # (This cuts out the empty black space around your drawing)
    coords = cv2.findNonZero(img)
    x, y, w, h = cv2.boundingRect(coords)

    # Crop the image to just the digit
    crop = img[y:y+h, x:x+w]

    # 3. Resize while maintaining aspect ratio
    # We want it to fit into a 20x20 box (leaving 4px padding like MNIST)
    target_h, target_w = 20, 20

    # Calculate scale needed
    scale_h = target_h / h
    scale_w = target_w / w
    scale = min(scale_h, scale_w) # Use the smaller scale to fit fully

    new_h, new_w = int(h * scale), int(w * scale)
    resized_crop = cv2.resize(crop, (new_w, new_h))

    # 4. Paste into center of a 28x28 black image
    final_img = np.zeros((28, 28), dtype=np.uint8)

    # Calculate centering offsets
    y_off = (28 - new_h) // 2
    x_off = (28 - new_w) // 2

    final_img[y_off:y_off+new_h, x_off:x_off+new_w] = resized_crop

    # Normalize
    final_img = final_img / 255.0

    # Reshape based on model input (Fixing shape mismatch automatically)
    input_shape = model.input_shape
    if input_shape and len(input_shape) > 1 and input_shape[1] == 784:
        # Flattened input
        return final_img.reshape(1, 784)
    else:
        # 3D input (28, 28, 1)
        return final_img.reshape(1, 28, 28, 1)

# 3. Predict Button
if st.button('Predict'):
    if canvas_result.image_data is not None:
        # Check if the user actually drew something (sum of pixels > 0)
        if np.sum(canvas_result.image_data) == 0:
             st.warning("Please draw a digit first!")
        else:
            try:
                # Use the new smart processing function
                processed_img = process_image(canvas_result.image_data)

                # Predict
                prediction = model.predict(processed_img)
                digit = np.argmax(prediction)

                st.success(f"## Predicted Digit: {digit}")

                # Show probability bar chart
                st.bar_chart(prediction[0])

                # OPTIONAL: Show what the model actually sees (for debugging)
                # st.image(processed_img.reshape(28,28), caption="What the model sees", width=100)

            except Exception as e:
                st.error(f"Error: {e}")
    else:
        st.warning("Please draw something first!")